"""
Machine Learning based complaint analyzer for IPC section classification.
This module uses NLP techniques to analyze complaint text and determine
relevant IPC sections that may apply.
"""

import re
import nltk
import numpy as np
import pandas as pd
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.preprocessing import MultiLabelBinarizer
import pickle
import os
import logging
from extensions import db
from models import LegalSection

# Configure logging
logger = logging.getLogger(__name__)

# Download required NLTK resources
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('wordnet', quiet=True)
except Exception as e:
    logger.warning(f"Failed to download NLTK resources: {str(e)}")

# Create a simple lemmatizer class as a fallback
class SimpleLemmatizer:
    def lemmatize(self, word):
        """Simple lemmatizer that just returns the word unchanged"""
        return word

# Initialize lemmatizer and stopwords
try:
    # Try to download wordnet again if it's not properly loaded
    try:
        nltk.download('wordnet', quiet=True)
        nltk.download('omw-1.4', quiet=True)  # Open Multilingual WordNet
    except Exception as download_error:
        logger.warning(f"Error downloading additional NLTK data: {str(download_error)}")

    # Try to use the NLTK lemmatizer
    lemmatizer = WordNetLemmatizer()
    # Test the lemmatizer with a simple word to ensure it works
    test_word = lemmatizer.lemmatize('test')
    logger.info(f"Lemmatizer initialized successfully, test: 'test' -> '{test_word}'")

    # Initialize stopwords
    stop_words = set(stopwords.words('english'))
except Exception as e:
    logger.warning(f"Error initializing NLP components: {str(e)}")
    # Fallback to our simple lemmatizer and empty stopwords
    lemmatizer = SimpleLemmatizer()
    stop_words = set()
    logger.info("Using fallback SimpleLemmatizer")

# Add domain-specific stopwords
legal_stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'if', 'then', 'else', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'}
stop_words.update(legal_stopwords)

# Model file paths
MODEL_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'ml_models')
os.makedirs(MODEL_DIR, exist_ok=True)
VECTORIZER_PATH = os.path.join(MODEL_DIR, 'tfidf_vectorizer.pkl')
CLASSIFIER_PATH = os.path.join(MODEL_DIR, 'ipc_classifier.pkl')
BINARIZER_PATH = os.path.join(MODEL_DIR, 'multilabel_binarizer.pkl')

# IPC keywords mapping - these are keywords associated with specific IPC sections
IPC_KEYWORDS = {
    # Offenses Against the Human Body
    '302': ['murder', 'kill', 'death', 'homicide', 'fatal', 'deceased', 'died', 'dead', 'slain', 'assassinated', 'executed', 'strangled', 'suffocated', 'poisoned', 'shot dead', 'stabbed to death', 'beaten to death'],
    '304': ['culpable homicide', 'not murder', 'death', 'killed', 'unintentional', 'without premeditation', 'heat of passion', 'provocation', 'sudden fight'],
    '304A': ['death by negligence', 'accidental death', 'rash act', 'negligent act', 'careless', 'reckless', 'accident', 'unintentional', 'traffic accident', 'medical negligence'],
    '304B': ['dowry death', 'bride', 'marriage', 'dowry', 'harassment', 'suicide', 'unnatural death', 'burn', 'in-laws', 'husband'],
    '307': ['attempt to murder', 'attempted murder', 'try to kill', 'intent to kill', 'shot', 'stabbed', 'attacked', 'life threatening', 'attempted homicide', 'failed murder', 'tried to kill'],
    '323': ['hurt', 'injury', 'assault', 'beat', 'hit', 'slap', 'punch', 'wound', 'bruise', 'physical harm', 'bodily harm', 'attacked', 'physical assault', 'voluntarily causing hurt'],
    '324': ['hurt by dangerous weapon', 'knife', 'sharp weapon', 'dangerous weapon', 'cut', 'stab', 'slash', 'weapon', 'iron rod', 'acid', 'burn', 'grievous', 'serious injury'],
    '325': ['grievous hurt', 'serious injury', 'fracture', 'disfiguration', 'permanent damage', 'disability', 'severe', 'grievous', 'broken bone', 'loss of vision', 'loss of hearing'],
    '326': ['grievous hurt by dangerous weapon', 'acid attack', 'serious injury with weapon', 'permanent damage', 'disfiguration with weapon', 'grievous with dangerous weapon'],
    '354': ['assault on woman', 'modesty', 'touch', 'outrage', 'female', 'inappropriate touching', 'harassment', 'molestation', 'groping', 'sexual harassment', 'forcibly', 'disrobe', 'unwanted advances'],
    '363': ['kidnapping', 'abduction', 'minor', 'child', 'taken away', 'forcibly taken', 'missing person', 'abducted', 'kidnapped', 'taken without consent'],
    '366': ['kidnapping woman', 'abduction of woman', 'compel marriage', 'forced marriage', 'illicit intercourse', 'forced to marry', 'abducted woman', 'kidnapped for marriage'],
    '376': ['rape', 'sexual assault', 'forced intercourse', 'without consent', 'sexual violence', 'violated', 'sexual abuse', 'non-consensual', 'sexual offence', 'penetration without consent'],

    # Property Offenses
    '378': ['theft', 'stealing', 'dishonestly take', 'movable property', 'without consent', 'took property', 'dishonest intention'],
    '379': ['theft', 'steal', 'stolen', 'took', 'property', 'belongings', 'missing', 'robbed', 'pickpocket', 'shoplifting', 'snatched', 'dishonestly took', 'stole from person'],
    '380': ['theft in dwelling', 'house theft', 'home burglary', 'break-in', 'house', 'dwelling', 'home', 'break', 'burglary', 'residence', 'apartment', 'stole from house', 'entered house to steal'],
    '381': ['theft by servant', 'employee theft', 'domestic help theft', 'servant stole', 'worker theft', 'staff theft', 'employee stole', 'domestic worker'],
    '382': ['theft after preparation to cause death', 'dangerous theft', 'armed theft', 'theft with weapon', 'prepared to hurt', 'theft with violence'],
    '384': ['extortion', 'threat', 'blackmail', 'demand', 'money', 'coercion', 'forced', 'pay up', 'threatening for money', 'forced to pay', 'illegal demand', 'under threat'],
    '386': ['extortion by putting in fear of death', 'death threat for money', 'extortion with deadly threat', 'pay or die', 'life threatening extortion'],
    '390': ['robbery', 'theft with force', 'forceful theft', 'violent theft', 'snatching with force'],
    '392': ['robbery', 'force', 'threat', 'weapon', 'steal', 'property', 'violence', 'forcibly took', 'snatched', 'mugging', 'armed robbery', 'violent theft', 'forceful stealing'],
    '395': ['dacoity', 'gang robbery', 'armed gang', 'robbery', 'group', 'five', 'persons', 'bandits', 'gang of thieves', 'armed group robbery', 'five or more robbers'],
    '397': ['robbery with deadly weapon', 'armed robbery', 'robbery with gun', 'robbery with knife', 'deadly weapon during robbery'],
    '398': ['robbery with attempt to cause death', 'deadly robbery', 'attempted murder during robbery', 'life-threatening robbery'],
    '406': ['criminal breach of trust', 'misappropriation', 'property', 'dishonest', 'entrusted', 'embezzlement', 'misused funds', 'dishonestly used', 'entrusted property', 'betrayed trust', 'fiduciary breach'],
    '409': ['breach of trust by public servant', 'government employee fraud', 'official misappropriation', 'public servant embezzlement', 'government funds misuse'],
    '415': ['cheating', 'deception', 'fraud', 'deceive', 'fraudulently', 'misrepresentation', 'false promise', 'dishonest inducement'],
    '420': ['cheating', 'fraud', 'deceive', 'dishonest', 'scam', 'false', 'misrepresentation', 'fraudulent', 'defrauded', 'duped', 'swindled', 'fake', 'counterfeit', 'ponzi scheme', 'fraudulent scheme'],
    '441': ['criminal trespass', 'unlawful entry', 'illegal entry', 'entered property', 'without permission', 'unauthorized entry'],
    '447': ['criminal trespass', 'trespass', 'unlawful entry', 'entered property', 'unauthorized access', 'illegal entry'],
    '448': ['house trespass', 'break into house', 'entered home', 'house breaking', 'unlawful home entry', 'trespass into dwelling'],
    '454': ['house breaking', 'break-in', 'burglary', 'broke into house', 'forced entry', 'house trespass for offense'],
    '457': ['house breaking at night', 'night burglary', 'break-in at night', 'night-time house trespass', 'nocturnal break-in'],
    '463': ['forgery', 'fake document', 'false document', 'forged', 'counterfeit document', 'fraudulent document', 'document fraud'],
    '465': ['punishment for forgery', 'forged document', 'fake document', 'false document', 'document fraud'],
    '468': ['forgery for cheating', 'forged document for fraud', 'fake document for deception', 'fraudulent document for cheating'],
    '471': ['using forged document', 'used fake document', 'submitted false document', 'presented forged document', 'relied on counterfeit document'],
    '489A': ['counterfeiting currency', 'fake money', 'counterfeit notes', 'forged currency', 'fake currency', 'counterfeit coins'],

    # Offenses Against Public Tranquility
    '143': ['unlawful assembly', 'illegal gathering', 'prohibited assembly', 'unlawful group', 'illegal meeting'],
    '147': ['rioting', 'riot', 'violent protest', 'mob violence', 'violent disorder', 'public disturbance', 'violent crowd'],
    '153A': ['promoting enmity between groups', 'hate speech', 'communal hatred', 'religious disharmony', 'inciting hatred', 'promoting disharmony'],
    '160': ['affray', 'public fight', 'fighting in public', 'public disturbance', 'brawl', 'public violence'],

    # Offenses Against Public Servants
    '186': ['obstructing public servant', 'preventing official duty', 'hindering public servant', 'obstructed officer', 'interfered with official'],
    '189': ['threat to public servant', 'threatened official', 'intimidated officer', 'threatened government employee'],

    # Offenses Against Marriage
    '493': ['cohabitation by deceit', 'false marriage', 'fraudulent marriage', 'deceived into marriage', 'fake marriage'],
    '494': ['bigamy', 'second marriage', 'married again', 'multiple spouses', 'two wives', 'two husbands'],
    '498A': ['cruelty by husband or relatives', 'domestic violence', 'dowry harassment', 'marital cruelty', 'husband harassment', 'in-laws harassment', 'wife beating', 'domestic abuse', 'matrimonial cruelty'],

    # Defamation
    '499': ['defamation', 'slander', 'libel', 'damaged reputation', 'false statement', 'character assassination', 'defamatory statement'],
    '500': ['punishment for defamation', 'defamed', 'slandered', 'libeled', 'damaged reputation', 'defamatory'],

    # Criminal Intimidation and Insult
    '503': ['criminal intimidation', 'threatening', 'threat', 'intimidation', 'threatened harm', 'threatened injury'],
    '504': ['intentional insult', 'provocation', 'breach of peace', 'insulted', 'provoked', 'abused verbally', 'verbal abuse', 'insulting language', 'provocative words', 'incitement'],
    '506': ['criminal intimidation', 'threat', 'threatening', 'intimidation', 'threatened', 'fear', 'danger', 'death threat', 'threatened harm', 'threatened injury', 'threatened violence'],
    '507': ['criminal intimidation by anonymous communication', 'anonymous threat', 'threatening letter', 'anonymous intimidation'],
    '509': ['insult to modesty of woman', 'obscene gesture', 'lewd comment', 'vulgar remark', 'sexual harassment', 'eve teasing', 'indecent behavior', 'obscene act', 'insulted woman'],

    # Attempts and Abetment
    '511': ['attempting to commit offense', 'attempted crime', 'tried to commit', 'attempt to commit', 'unsuccessful attempt'],

    # Cyber Crimes (IT Act sections commonly used with IPC)
    '66': ['computer related offense', 'hacking', 'data theft', 'unauthorized access', 'computer fraud', 'cyber crime'],
    '66A': ['offensive electronic message', 'threatening email', 'abusive message', 'harassing online', 'offensive communication'],
    '66C': ['identity theft', 'stolen password', 'impersonation online', 'digital identity theft', 'electronic signature theft'],
    '66D': ['cheating by impersonation using computer', 'online impersonation', 'fake profile', 'digital impersonation', 'electronic fraud'],
    '66E': ['privacy violation', 'private image', 'unauthorized image capture', 'privacy breach', 'private area photograph'],
    '66F': ['cyber terrorism', 'digital attack', 'computer system attack', 'critical infrastructure attack', 'cyber attack'],
    '67': ['publishing obscene material', 'obscene content', 'pornographic content', 'indecent material online', 'electronic obscenity'],
    '67A': ['publishing sexually explicit content', 'electronic pornography', 'explicit digital content', 'sexual content online'],
    '67B': ['child pornography', 'minor explicit content', 'child sexual abuse material', 'underage explicit content']
}

def preprocess_text(text):
    """
    Preprocess the text by removing special characters,
    converting to lowercase, tokenizing, removing stopwords, and lemmatizing
    """
    if not text:
        return ""

    try:
        # Convert to lowercase and remove special characters
        text = re.sub(r'[^\w\s]', ' ', text.lower())

        try:
            # Try to tokenize with NLTK
            tokens = word_tokenize(text)
        except Exception as tokenize_error:
            logger.warning(f"Error tokenizing with NLTK: {str(tokenize_error)}")
            # Simple fallback tokenization
            tokens = text.split()

        # Remove stopwords and lemmatize
        try:
            # Process tokens one by one to isolate any problematic tokens
            processed_tokens = []
            for token in tokens:
                if token not in stop_words:
                    try:
                        lemmatized = lemmatizer.lemmatize(token)
                        processed_tokens.append(lemmatized)
                    except Exception as token_error:
                        logger.warning(f"Error lemmatizing token '{token}': {str(token_error)}")
                        # If lemmatization fails for a specific token, use the original token
                        processed_tokens.append(token)
        except Exception as lemmatize_error:
            logger.warning(f"Error in lemmatization process: {str(lemmatize_error)}")
            # Fallback to just removing stopwords
            processed_tokens = [token for token in tokens if token not in stop_words]

        return ' '.join(processed_tokens)
    except Exception as e:
        logger.error(f"Error in text preprocessing: {str(e)}")
        # Return simplified text as fallback
        return text.lower()

def extract_features(text):
    """Extract features from the text using TF-IDF vectorization"""
    try:
        # Load the vectorizer if it exists
        if os.path.exists(VECTORIZER_PATH):
            with open(VECTORIZER_PATH, 'rb') as f:
                vectorizer = pickle.load(f)
            return vectorizer.transform([preprocess_text(text)])
        else:
            # If no vectorizer exists, create a simple one
            vectorizer = TfidfVectorizer(max_features=5000)
            vectorizer.fit([preprocess_text(text)])

            # Save the vectorizer for future use
            with open(VECTORIZER_PATH, 'wb') as f:
                pickle.dump(vectorizer, f)

            return vectorizer.transform([preprocess_text(text)])
    except Exception as e:
        logger.error(f"Error extracting features: {str(e)}")
        return None

def keyword_based_analysis(text):
    """
    Analyze the complaint text using keyword matching to identify potential IPC sections.
    This is a fallback method when ML model is not available.
    """
    text = text.lower()
    matches = {}

    for section, keywords in IPC_KEYWORDS.items():
        score = 0
        for keyword in keywords:
            if keyword in text:
                score += 1

        if score > 0:
            # Calculate a confidence score (0-1) based on keyword matches
            confidence = min(score / len(keywords) * 1.5, 1.0)
            matches[section] = confidence

    # Sort by confidence score and return top matches
    sorted_matches = sorted(matches.items(), key=lambda x: x[1], reverse=True)
    return sorted_matches

def train_model(training_data=None):
    """
    Train a machine learning model to classify complaints into IPC sections.
    If training_data is not provided, it will use a small default dataset.

    Args:
        training_data: A list of tuples (complaint_text, [ipc_sections])
    """
    try:
        # If no training data is provided, use a small default dataset
        if not training_data:
            # Enhanced dataset for better training
            training_data = [
                # Section 302 - Murder
                ("The accused murdered the victim by stabbing him multiple times.", ["302"]),
                ("The victim was killed by the accused with a knife.", ["302"]),
                ("The accused shot and killed the victim during an argument.", ["302"]),
                ("The accused strangled the victim to death.", ["302"]),
                ("The victim died due to poisoning administered by the accused.", ["302"]),
                ("The accused hit the victim on the head with a heavy object causing death.", ["302"]),
                ("The accused deliberately ran over the victim with a car, killing them instantly.", ["302"]),

                # Section 307 - Attempt to Murder
                ("The accused attempted to kill the victim by firing a gun.", ["307"]),
                ("The accused tried to stab the victim but was stopped.", ["307"]),
                ("The accused poisoned the food but the victim survived after hospital treatment.", ["307"]),
                ("The accused pushed the victim from a height with intent to kill, but the victim survived.", ["307"]),
                ("The accused attacked the victim with a deadly weapon but failed to kill them.", ["307"]),
                ("The accused tried to strangle the victim but was interrupted.", ["307"]),

                # Section 323 - Voluntarily causing hurt
                ("The accused assaulted the victim causing injuries.", ["323"]),
                ("The accused slapped and punched the victim.", ["323"]),
                ("The accused beat the victim with bare hands.", ["323"]),
                ("The victim was physically assaulted by the accused.", ["323"]),
                ("The accused pushed the victim causing them to fall and get injured.", ["323"]),

                # Section 324 - Voluntarily causing hurt by dangerous weapons
                ("The accused attacked the victim with a knife causing injuries.", ["324"]),
                ("The accused hit the victim with an iron rod.", ["324"]),
                ("The accused used a broken bottle to attack the victim.", ["324"]),
                ("The victim was injured when the accused attacked with a sharp object.", ["324"]),
                ("The accused threw acid at the victim causing burns.", ["324"]),

                # Section 354 - Assault or criminal force to woman with intent to outrage her modesty
                ("The accused inappropriately touched a woman without her consent.", ["354"]),
                ("The accused groped the woman in a public place.", ["354"]),
                ("The accused forcibly hugged the woman against her will.", ["354"]),
                ("The woman was molested by the accused in the elevator.", ["354"]),
                ("The accused pulled the woman's clothes with intent to disrobe her.", ["354"]),

                # Section 376 - Rape
                ("The accused sexually assaulted the victim.", ["376"]),
                ("The accused raped the victim at his residence.", ["376"]),
                ("The victim was sexually violated by the accused against her consent.", ["376"]),
                ("The accused committed sexual intercourse with the victim without consent.", ["376"]),

                # Section 379 - Theft
                ("The accused stole the victim's mobile phone.", ["379"]),
                ("The accused took the victim's wallet from their pocket.", ["379"]),
                ("The victim's laptop was stolen by the accused from the office.", ["379"]),
                ("The accused stole jewelry from the victim's bag.", ["379"]),
                ("The accused took the victim's bicycle without permission.", ["379"]),

                # Section 380 - Theft in dwelling house
                ("The accused broke into the victim's house and stole valuables.", ["380"]),
                ("The accused entered the house at night and stole electronics.", ["380"]),
                ("The victim's home was burglarized by the accused who stole cash and jewelry.", ["380"]),
                ("The accused stole items from the victim's apartment while they were away.", ["380"]),

                # Section 384 - Extortion
                ("The accused threatened the victim and demanded money.", ["384", "506"]),
                ("The accused blackmailed the victim for financial gain.", ["384"]),
                ("The victim was forced to pay money after being threatened by the accused.", ["384", "506"]),
                ("The accused extorted money by threatening to harm the victim's family.", ["384", "506"]),

                # Section 392 - Robbery
                ("The accused robbed the victim at knifepoint.", ["392"]),
                ("The accused snatched the victim's purse using force.", ["392"]),
                ("The victim was robbed by the accused who threatened with a weapon.", ["392"]),
                ("The accused forcibly took the victim's belongings after assaulting them.", ["392", "323"]),

                # Section 395 - Dacoity
                ("A group of five armed men robbed the bank.", ["395"]),
                ("The shop was looted by a gang of seven people.", ["395"]),
                ("Five or more persons committed robbery at the victim's house.", ["395"]),
                ("A gang of armed dacoits attacked and robbed the village.", ["395"]),

                # Section 406 - Criminal breach of trust
                ("The accused misappropriated the funds entrusted to him.", ["406"]),
                ("The accused was given jewelry for safekeeping but sold it.", ["406"]),
                ("The victim gave money to the accused for investment but the accused used it for personal expenses.", ["406"]),
                ("The accused was entrusted with documents but destroyed them.", ["406"]),

                # Section 420 - Cheating and dishonestly inducing delivery of property
                ("The accused cheated the victim by selling fake property documents.", ["420"]),
                ("The accused fraudulently took money promising a job that didn't exist.", ["420"]),
                ("The victim was deceived into investing in a fake company by the accused.", ["420"]),
                ("The accused sold counterfeit products claiming them to be genuine.", ["420"]),
                ("The accused ran a Ponzi scheme defrauding multiple victims.", ["420"]),

                # Section 498A - Husband or relative of husband of a woman subjecting her to cruelty
                ("The husband and in-laws harassed the woman for dowry.", ["498A"]),
                ("The woman was subjected to cruelty by her husband.", ["498A"]),
                ("The victim's husband and mother-in-law tortured her for not bringing enough dowry.", ["498A"]),
                ("The woman was physically and mentally abused by her husband.", ["498A"]),

                # Section 504 - Intentional insult with intent to provoke breach of the peace
                ("The accused verbally abused the victim in public.", ["504"]),
                ("The accused used derogatory language to insult the victim.", ["504"]),
                ("The accused deliberately provoked the victim with insulting words.", ["504"]),
                ("The victim was publicly humiliated by the accused's insulting remarks.", ["504"]),

                # Section 506 - Criminal intimidation
                ("The accused threatened to kill the victim.", ["506"]),
                ("The accused threatened to harm the victim's children if demands weren't met.", ["506"]),
                ("The victim received death threats from the accused.", ["506"]),
                ("The accused intimidated the victim with threats of violence.", ["506"]),

                # Section 509 - Word, gesture or act intended to insult the modesty of a woman
                ("The accused made inappropriate gestures towards a woman.", ["509"]),
                ("The accused passed lewd comments at the woman.", ["509"]),
                ("The woman was harassed by the accused making obscene gestures.", ["509"]),
                ("The accused stalked the woman and made vulgar comments.", ["509"]),

                # Multiple sections
                ("The accused broke into the house, stole valuables, and assaulted the owner.", ["380", "323"]),
                ("The accused kidnapped the victim and demanded ransom from the family.", ["363", "384"]),
                ("The accused forged documents to fraudulently sell the victim's property.", ["420", "468"]),
                ("The accused threatened witnesses to prevent them from testifying in court.", ["506", "195"]),
                ("The accused was driving under the influence and caused a fatal accident.", ["304A", "279"]),
                ("The accused cyberstalked the victim and posted obscene content about them online.", ["509", "67A"]),
                ("The accused trespassed into the victim's property and damaged furniture.", ["447", "427"])
            ]

        # Extract texts and labels
        texts = [item[0] for item in training_data]
        labels = [item[1] for item in training_data]

        # Preprocess texts
        processed_texts = [preprocess_text(text) for text in texts]

        # Create and fit multilabel binarizer
        mlb = MultiLabelBinarizer()
        y = mlb.fit_transform(labels)

        # Create a pipeline with multiple classifiers
        # We'll train multiple models and choose the best one
        classifiers = {
            'logistic_regression': OneVsRestClassifier(LogisticRegression(solver='liblinear', max_iter=1000, C=1.0)),
            'random_forest': OneVsRestClassifier(RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)),
            'linear_svc': OneVsRestClassifier(LinearSVC(C=1.0, max_iter=1000, random_state=42))
        }

        # Create a TF-IDF vectorizer with n-grams
        vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 2),  # Use both unigrams and bigrams
            min_df=2,            # Minimum document frequency
            max_df=0.9,          # Maximum document frequency
            sublinear_tf=True    # Apply sublinear tf scaling (log(tf))
        )

        # Transform the text data
        X = vectorizer.fit_transform(processed_texts)

        # Train all classifiers
        trained_classifiers = {}
        best_classifier = None
        best_score = 0

        for name, clf in classifiers.items():
            try:
                logger.info(f"Training classifier: {name}")
                clf.fit(X, y)

                # Simple evaluation on training data (in a real system, we would use cross-validation)
                score = clf.score(X, y)
                logger.info(f"Classifier {name} score: {score:.4f}")

                trained_classifiers[name] = clf

                # Keep track of the best classifier
                if score > best_score:
                    best_score = score
                    best_classifier = clf
            except Exception as e:
                logger.error(f"Error training classifier {name}: {str(e)}")

        # If no classifier worked, fall back to logistic regression
        if best_classifier is None:
            logger.warning("All classifiers failed, falling back to basic logistic regression")
            best_classifier = OneVsRestClassifier(LogisticRegression(solver='liblinear', max_iter=1000))
            best_classifier.fit(X, y)

        # Use the best classifier
        classifier = best_classifier
        logger.info(f"Using best classifier with score: {best_score:.4f}")

        # Save the model components
        with open(VECTORIZER_PATH, 'wb') as f:
            pickle.dump(vectorizer, f)

        with open(CLASSIFIER_PATH, 'wb') as f:
            pickle.dump(classifier, f)

        with open(BINARIZER_PATH, 'wb') as f:
            pickle.dump(mlb, f)

        logger.info("ML model trained and saved successfully")
        return True
    except Exception as e:
        logger.error(f"Error training model: {str(e)}")
        return False

def predict_ipc_sections(complaint_text):
    """
    Predict IPC sections for a given complaint text.

    Args:
        complaint_text: The text of the complaint

    Returns:
        A list of dictionaries with section codes and confidence scores
    """
    try:
        # Check if model exists
        if not (os.path.exists(VECTORIZER_PATH) and
                os.path.exists(CLASSIFIER_PATH) and
                os.path.exists(BINARIZER_PATH)):
            logger.warning("ML model not found. Training a new model...")
            train_model()

        # Load model components
        with open(VECTORIZER_PATH, 'rb') as f:
            vectorizer = pickle.load(f)

        with open(CLASSIFIER_PATH, 'rb') as f:
            classifier = pickle.load(f)

        with open(BINARIZER_PATH, 'rb') as f:
            mlb = pickle.load(f)

        # Preprocess and vectorize the text
        processed_text = preprocess_text(complaint_text)
        X = vectorizer.transform([processed_text])

        # Get prediction probabilities
        y_pred_proba = classifier.predict_proba(X)

        # Get the classes (IPC sections)
        classes = mlb.classes_

        # Create a list of (section, probability) tuples
        section_probs = [(section, prob) for section, prob in zip(classes, y_pred_proba[0])]

        # Sort by probability (descending) and filter those with probability > 0.2
        section_probs = sorted([(s, p) for s, p in section_probs if p > 0.2], key=lambda x: x[1], reverse=True)

        # If ML model doesn't find good matches, fall back to keyword-based analysis
        if not section_probs:
            logger.info("ML model didn't find strong matches, using keyword analysis")
            section_probs = keyword_based_analysis(complaint_text)

        # Convert to the expected format with better explanations
        results = []
        for section_code, confidence in section_probs:
            # Get section details from database
            section = LegalSection.query.filter_by(code=section_code).first()

            # Generate a more detailed explanation of relevance
            relevance_explanation = generate_relevance_explanation(complaint_text, section_code, confidence)

            if section:
                results.append({
                    "section_code": section.code,
                    "section_name": section.name,
                    "section_description": section.description,
                    "confidence": float(confidence),
                    "relevance": relevance_explanation,
                    "keywords_matched": find_matching_keywords(complaint_text, section_code)
                })
            else:
                # If section not in database, provide basic info
                results.append({
                    "section_code": section_code,
                    "section_name": f"IPC Section {section_code}",
                    "section_description": "Description not available",
                    "confidence": float(confidence),
                    "relevance": relevance_explanation,
                    "keywords_matched": find_matching_keywords(complaint_text, section_code)
                })

        return results
    except Exception as e:
        logger.error(f"Error predicting IPC sections: {str(e)}")
        # Fall back to keyword-based analysis
        section_probs = keyword_based_analysis(complaint_text)

        results = []
        for section_code, confidence in section_probs:
            # Get section details from database
            section = LegalSection.query.filter_by(code=section_code).first()

            # Generate a more detailed explanation of relevance
            relevance_explanation = generate_relevance_explanation(complaint_text, section_code, confidence)

            if section:
                results.append({
                    "section_code": section.code,
                    "section_name": section.name,
                    "section_description": section.description,
                    "confidence": float(confidence),
                    "relevance": relevance_explanation,
                    "keywords_matched": find_matching_keywords(complaint_text, section_code)
                })
            else:
                results.append({
                    "section_code": section_code,
                    "section_name": f"IPC Section {section_code}",
                    "section_description": "Description not available",
                    "confidence": float(confidence),
                    "relevance": relevance_explanation,
                    "keywords_matched": find_matching_keywords(complaint_text, section_code)
                })

        return results

def find_matching_keywords(text, section_code):
    """
    Find keywords in the text that match the given IPC section

    Args:
        text: The complaint text
        section_code: The IPC section code

    Returns:
        list: Matching keywords
    """
    if not text or section_code not in IPC_KEYWORDS:
        return []

    text = text.lower()
    matching_keywords = []

    for keyword in IPC_KEYWORDS.get(section_code, []):
        # Check for exact word match with word boundaries
        if re.search(r'\b' + re.escape(keyword) + r'\b', text):
            matching_keywords.append(keyword)

    return matching_keywords

def generate_relevance_explanation(text, section_code, confidence):
    """
    Generate a detailed explanation of why a section is relevant to the complaint

    Args:
        text: The complaint text
        section_code: The IPC section code
        confidence: The confidence score

    Returns:
        str: Explanation of relevance
    """
    # Get matching keywords
    matching_keywords = find_matching_keywords(text, section_code)

    # Get section information
    section = LegalSection.query.filter_by(code=section_code).first()
    section_name = section.name if section else f"Section {section_code}"

    # Generate explanation based on confidence level
    if confidence > 0.8:
        confidence_level = "very high"
    elif confidence > 0.6:
        confidence_level = "high"
    elif confidence > 0.4:
        confidence_level = "moderate"
    elif confidence > 0.2:
        confidence_level = "low"
    else:
        confidence_level = "very low"

    # Base explanation
    explanation = f"This complaint shows {confidence_level} relevance (score: {confidence:.2f}) to {section_name}."

    # Add keyword information if available
    if matching_keywords:
        if len(matching_keywords) == 1:
            explanation += f" The key term '{matching_keywords[0]}' was found in the complaint."
        else:
            keywords_str = ", ".join([f"'{k}'" for k in matching_keywords[:-1]]) + f" and '{matching_keywords[-1]}'"
            explanation += f" Key terms {keywords_str} were found in the complaint."

    # Add section-specific explanations
    if section_code == '302':
        explanation += " This section deals with murder and is applicable when there is death caused with the intention of causing death."
    elif section_code == '304A':
        explanation += " This section deals with death caused by negligence, not amounting to culpable homicide."
    elif section_code == '307':
        explanation += " This section applies to attempted murder cases where there was a clear intention to kill."
    elif section_code == '323' or section_code == '324':
        explanation += " This section applies to cases involving physical assault or causing hurt."
    elif section_code == '354':
        explanation += " This section applies to cases involving assault or criminal force against a woman with intent to outrage her modesty."
    elif section_code == '376':
        explanation += " This section applies to cases of rape or sexual assault."
    elif section_code == '379' or section_code == '380':
        explanation += " This section applies to cases of theft or stealing property."
    elif section_code == '392' or section_code == '395':
        explanation += " This section applies to robbery cases where theft involves force or threat."
    elif section_code == '406':
        explanation += " This section applies to criminal breach of trust cases where property entrusted is misappropriated."
    elif section_code == '420':
        explanation += " This section applies to cases of cheating and dishonestly inducing delivery of property."
    elif section_code == '498A':
        explanation += " This section applies to cases of cruelty by husband or relatives of husband against a woman."
    elif section_code == '504' or section_code == '506':
        explanation += " This section applies to cases involving intentional insult or criminal intimidation."

    return explanation

def analyze_complaint(complaint_text):
    """
    Analyze a complaint text and return relevant IPC sections.
    This is the main function to be called from other modules.

    Args:
        complaint_text: The text of the complaint

    Returns:
        A dictionary with sections and analysis
    """
    if not complaint_text:
        return {"sections": []}

    # Get IPC section predictions
    sections = predict_ipc_sections(complaint_text)

    # Return in the expected format
    return {
        "sections": sections
    }
